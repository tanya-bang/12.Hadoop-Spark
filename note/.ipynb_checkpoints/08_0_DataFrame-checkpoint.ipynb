{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "503abec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b998ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525a7bed",
   "metadata": {},
   "source": [
    "# 1. DataFrame 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f981045-4dfc-44e5-809a-100de5e5ebe0",
   "metadata": {},
   "source": [
    "### SparkSession.createDataFrame(data, **schema=None**, samplingRatio=None, verifySchema=True)\n",
    "- data : RDD or iterable\n",
    "- **scheam : pyspark.sql.types.DataType, str or list, optional**, 지정하지 않으면 스파크가 기본으로 생성.\n",
    "  \n",
    "- samplingRatio : the sample ratio of rows used for inferring, 스키마가 입력되지 않으면 데이터로 유추해야함(이때 확인할 data비율)\n",
    "    - 인수값이 None이면 전달된 data의 첫번째 data만 읽어서 스키마 유추\n",
    "\n",
    "-  verifySchema : verify data types of every row against schema. Enabled by default\n",
    "\n",
    "- SparkSession 객체를 사용해 DataFrame을 생성할 수 있다.\n",
    "- SparkSession 객체는 pyspark shell을 실행할 때 spark 라는 이름으로 미리 생성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7852f6",
   "metadata": {},
   "source": [
    "## Row 객체를 사용해 생성하기\n",
    "\n",
    "- row : DataFrame에서의 한 행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98186e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab1f57b4-bd53-446b-8676-496fbd1c9264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2cb74f2-d56d-4a70-9476-49c22979fc95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    A row in :class:`DataFrame`.\u001b[0m\n",
       "\u001b[0;34m    The fields in it can be accessed:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    * like attributes (``row.key``)\u001b[0m\n",
       "\u001b[0;34m    * like dictionary values (``row[key]``)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    ``key in row`` will search through row keys.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Row can be used to create a row object by using named arguments.\u001b[0m\n",
       "\u001b[0;34m    It is not allowed to omit a named argument to represent that the value is\u001b[0m\n",
       "\u001b[0;34m    None or missing. This should be explicitly set to None in this case.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. versionchanged:: 3.0.0\u001b[0m\n",
       "\u001b[0;34m        Rows created from named arguments no longer have\u001b[0m\n",
       "\u001b[0;34m        field names sorted alphabetically and will be ordered in the position as\u001b[0m\n",
       "\u001b[0;34m        entered.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> row = Row(name=\"Alice\", age=11)\u001b[0m\n",
       "\u001b[0;34m    >>> row\u001b[0m\n",
       "\u001b[0;34m    Row(name='Alice', age=11)\u001b[0m\n",
       "\u001b[0;34m    >>> row['name'], row['age']\u001b[0m\n",
       "\u001b[0;34m    ('Alice', 11)\u001b[0m\n",
       "\u001b[0;34m    >>> row.name, row.age\u001b[0m\n",
       "\u001b[0;34m    ('Alice', 11)\u001b[0m\n",
       "\u001b[0;34m    >>> 'name' in row\u001b[0m\n",
       "\u001b[0;34m    True\u001b[0m\n",
       "\u001b[0;34m    >>> 'wrong_key' in row\u001b[0m\n",
       "\u001b[0;34m    False\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Row also can be used to create another Row like class, then it\u001b[0m\n",
       "\u001b[0;34m    could be used to create Row objects, such as\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> Person = Row(\"name\", \"age\")\u001b[0m\n",
       "\u001b[0;34m    >>> Person\u001b[0m\n",
       "\u001b[0;34m    <Row('name', 'age')>\u001b[0m\n",
       "\u001b[0;34m    >>> 'name' in Person\u001b[0m\n",
       "\u001b[0;34m    True\u001b[0m\n",
       "\u001b[0;34m    >>> 'wrong_key' in Person\u001b[0m\n",
       "\u001b[0;34m    False\u001b[0m\n",
       "\u001b[0;34m    >>> Person(\"Alice\", 11)\u001b[0m\n",
       "\u001b[0;34m    Row(name='Alice', age=11)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    This form can also be used to create rows as tuple values, i.e. with unnamed\u001b[0m\n",
       "\u001b[0;34m    fields.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> row1 = Row(\"Alice\", 11)\u001b[0m\n",
       "\u001b[0;34m    >>> row2 = Row(name=\"Alice\", age=11)\u001b[0m\n",
       "\u001b[0;34m    >>> row1 == row2\u001b[0m\n",
       "\u001b[0;34m    True\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can not use both args \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m\"and kwargs to create Row\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# create row objects\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# create row class or objects\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0masDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Return as a dict\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        recursive : bool, optional\u001b[0m\n",
       "\u001b[0;34m            turns the nested Rows to dict (default: False).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Notes\u001b[0m\n",
       "\u001b[0;34m        -----\u001b[0m\n",
       "\u001b[0;34m        If a row contains duplicate field names, e.g., the rows of a join\u001b[0m\n",
       "\u001b[0;34m        between two :class:`DataFrame` that both have the fields of same names,\u001b[0m\n",
       "\u001b[0;34m        one of the duplicate fields will be selected by ``asDict``. ``__getitem__``\u001b[0m\n",
       "\u001b[0;34m        will also return one of the duplicate fields, however returned value might\u001b[0m\n",
       "\u001b[0;34m        be different to ``asDict``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Examples\u001b[0m\n",
       "\u001b[0;34m        --------\u001b[0m\n",
       "\u001b[0;34m        >>> Row(name=\"Alice\", age=11).asDict() == {'name': 'Alice', 'age': 11}\u001b[0m\n",
       "\u001b[0;34m        True\u001b[0m\n",
       "\u001b[0;34m        >>> row = Row(key=1, value=Row(name='a', age=2))\u001b[0m\n",
       "\u001b[0;34m        >>> row.asDict() == {'key': 1, 'value': Row(name='a', age=2)}\u001b[0m\n",
       "\u001b[0;34m        True\u001b[0m\n",
       "\u001b[0;34m        >>> row.asDict(True) == {'key': 1, 'value': {'name': 'a', 'age': 2}}\u001b[0m\n",
       "\u001b[0;34m        True\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__fields__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot convert a Row class into dict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mdef\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__fields__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# let object acts like class\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"create new Row object\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can not create Row with fields %s, expected %d values \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m\"but got %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0m_create_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# it will be slow when it has many fields,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# but this will not be used in normal cases\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# it will be slow when it has many fields,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# but this will not be used in normal cases\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'__fields__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Row is read-only\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Returns a tuple so Python knows how to pickle Row.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__fields__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_create_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Printable representation of Row used in Python REPL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__fields__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"Row(%s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s=%r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"<Row(%s)>\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/spark/python/pyspark/sql/types.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Spark.Row 클래스\n",
    "??Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e48144bd-b282-4432-a437-79ea3c78ce76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(name='김철수', age=15, birth=datetime.date(1996, 7, 22))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'김철수'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.Row는 명명된 인수를 사용하여 행 개체를 만드는 데 사용할 수 있음\n",
    "row = Row(name='김철수', age=15, birth=date(1996,7,22))\n",
    "row\n",
    "row['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96b22837-417e-43c8-bb64-c372ca49c263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, age: bigint, birth: date]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  name|age|     birth|\n",
      "+------+---+----------+\n",
      "|김철수| 15|1996-07-22|\n",
      "|이제동| 20|1991-05-10|\n",
      "|홍진호| 22|1992-02-22|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spakr DF 생성\n",
    "# Row class의 생성자로 keyword args를 전달해 생성\n",
    "df = spark.createDataFrame([\n",
    "     Row(name='김철수', age=15, birth=date(1996,7,22)),\n",
    "     Row(name='이제동', age=20, birth=date(1991,5,10)),\n",
    "     Row(name='홍진호', age=22, birth=date(1992,2,22))\n",
    "])\n",
    "df #지연연산\n",
    "\n",
    "# 실행결과값: DataFrame[name: string, age: bigint, birth: date]\n",
    "    #이것이 스키마. 즉, 스키마란 생성될 df의 기본정보 - 컬럼명:컬럼타입\n",
    "\n",
    "# df 확인: action진행 - show(n): n개의 행 출력, 생략하면 기본값 n=20\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2aca89-d490-4094-815d-5d9a543d2236",
   "metadata": {},
   "source": [
    "- 논리적 연산 계획을 최적화 하기 위해 schema 사용\n",
    "- 지정하지 않으면 자동생성\n",
    "- 전체 스키마 확인\n",
    "    - df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb710e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- birth: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 스키마(구조) 확인 - 자동생성됨(data보고 spark가 유추, null 허용 여부는 대부분 허용함 - 허용해야 spark가 편하기 때문에...)\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54c584",
   "metadata": {},
   "source": [
    "## schema를 명시하여 DataFrame 생성\n",
    "- 사용자 명시 스키마를 활용\n",
    "- schema= 인수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2295388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  name|age|     birth|\n",
      "+------+---+----------+\n",
      "|김철수| 15|1996-07-22|\n",
      "|이제동| 20|1991-05-10|\n",
      "|홍진호| 22|1992-02-22|\n",
      "+------+---+----------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- birth: date (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 튜플에 데이터를 저장하고 스키마(pands df의 column)를 직접 지정, 문자열로 지정\n",
    "df2 = spark.createDataFrame([\n",
    "     Row(name='김철수', age=15, birth=date(1996,7,22)),\n",
    "     Row(name='이제동', age=20, birth=date(1991,5,10)),\n",
    "     Row(name='홍진호', age=22, birth=date(1992,2,22))\n",
    "], schema='name string, age int, birth date')\n",
    "df2.show()\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523fee7a",
   "metadata": {},
   "source": [
    "## StructType 객체를 사용해 Schema 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec49fd94-a270-4afb-8951-2aea1346d5b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnullable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"A field in :class:`StructType`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    name : str\u001b[0m\n",
       "\u001b[0;34m        name of the field.\u001b[0m\n",
       "\u001b[0;34m    dataType : :class:`DataType`\u001b[0m\n",
       "\u001b[0;34m        :class:`DataType` of the field.\u001b[0m\n",
       "\u001b[0;34m    nullable : bool, optional\u001b[0m\n",
       "\u001b[0;34m        whether the field can be null (None) or not.\u001b[0m\n",
       "\u001b[0;34m    metadata : dict, optional\u001b[0m\n",
       "\u001b[0;34m        a dict from string to simple type that can be toInternald to JSON automatically\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> (StructField(\"f1\", StringType(), True)\u001b[0m\n",
       "\u001b[0;34m    ...      == StructField(\"f1\", StringType(), True))\u001b[0m\n",
       "\u001b[0;34m    True\u001b[0m\n",
       "\u001b[0;34m    >>> (StructField(\"f1\", StringType(), True)\u001b[0m\n",
       "\u001b[0;34m    ...      == StructField(\"f2\", StringType(), True))\u001b[0m\n",
       "\u001b[0;34m    False\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnullable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\\\n",
       "            \u001b[0;34m\"dataType %s should be an instance of %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"field name %s should be a string\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataType\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnullable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnullable\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0msimpleString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m'%s:%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimpleString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"StructField(%s,%s,%s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnullable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mjsonValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjsonValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"nullable\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnullable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfromJson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                           \u001b[0m_parse_datatype_json_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                           \u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nullable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                           \u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mneedConversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneedConversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtoInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfromInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtypeName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"StructField does not have typeName. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"Use typeName on its type explicitly instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/spark/python/pyspark/sql/types.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??StructField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ddecd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08545ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    ('김철수', 15, date(1996,7,22)),\n",
    "    ('이제동', 20, date(1991,5,10)),\n",
    "    ('홍진호', 22, date(1992,2,22))]\n",
    "\n",
    "# data = [\n",
    "#     ('김철수', 15, date(1996,7,22)),\n",
    "#     ('이제동', 20, date(1991,5,10)), #빈문자열 str타입이 스키마에 int로 구성해놓은 age 컬럼이라 타입오류 에러 발생\n",
    "#     ('홍진호', 22, date(1992,2,22))]\n",
    "\n",
    "# data = [\n",
    "#     ('김철수', 15, date(1996,7,22)),\n",
    "#     ('', 20, date(1991,5,10)), #빈문자열: null 처리의 의미로 전달 -> 스키마 nullable이 false임에도 df생성. 즉 '' null이아닌 정상데이터임\n",
    "#     ('홍진호', 22, date(1992,2,22))\n",
    "# ]\n",
    "\n",
    "# data = [\n",
    "#     ('김철수', 15, date(1996,7,22)),\n",
    "#     (None, 20, date(1991,5,10)), # None: python의 null값 표현- 스키마에 nullable이 false여서 에러 발생\n",
    "#     ('홍진호', 22, date(1992,2,22))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bae07e4-74f7-4edb-a203-8e5710afd88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StructField 식: StructField(name, dataType, nullable=True, metadata=None)\n",
    "# df의 열별로 StructField를 구성\n",
    "# 컬럼 type은 XXXType() 이라는 모듈 사용: eg-StringType(), IntegerType()\n",
    "schema = StructType([\n",
    "    StructField('name',StringType(), False),\n",
    "    StructField('age',IntegerType(), False),\n",
    "    StructField('birth',DateType(), False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54eca8b3-59ac-4bfa-9c46-46bdf92b274d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = false)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- birth: date (nullable = false)\n",
      "\n",
      "+------+---+----------+\n",
      "|  name|age|     birth|\n",
      "+------+---+----------+\n",
      "|김철수| 15|1996-07-22|\n",
      "|이제동| 20|1991-05-10|\n",
      "|홍진호| 22|1992-02-22|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.createDataFrame(data=data, schema=schema)\n",
    "df3.printSchema()\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0399d3a",
   "metadata": {},
   "source": [
    "## 중첩스키마적용\n",
    "- 컬럼의 데이터가 단일 데이터가 아닌 iter데이터인 경우\n",
    "    - 스키마를 컬럼의 원소값 각각에 대해 생성 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dfdd27c-2a44-44d4-b9e7-d8aa947d963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    ('김철수', 15, date(2022,7,22), ('010','1111','2222')),\n",
    "    ('이제동', 20, date(1991,5,10), ('010','3333','4444')),\n",
    "    ('홍진호', 22, date(1992,2,22), ('010','2222','2222'))]\n",
    "# StructField(name, dataType, nullable=True, metadata=None)\n",
    "schema = StructType([\n",
    "    StructField('name',StringType(), False, {'desc':'이름'}), # name 컬럼 null 불허\n",
    "    StructField('age',IntegerType(), False, {'desc':'나이'}),\n",
    "    StructField('birth',DateType(), False, {'desc':'생일'}),\n",
    "    StructField('phone',StructType([\n",
    "        StructField('phone1', StringType(), True),\n",
    "        StructField('phone2', StringType(), True),\n",
    "        StructField('phone3', StringType(), True)\n",
    "    ]), False, {'desc':'생일'}) #중첩스키마\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89f7431a-0fee-4feb-a63f-f606d2d1f4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = false)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- birth: date (nullable = false)\n",
      " |-- phone: struct (nullable = false)\n",
      " |    |-- phone1: string (nullable = true)\n",
      " |    |-- phone2: string (nullable = true)\n",
      " |    |-- phone3: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+\n",
      "|  name|age|     birth|            phone|\n",
      "+------+---+----------+-----------------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|\n",
      "|이제동| 20|1991-05-10|{010, 3333, 4444}|\n",
      "|홍진호| 22|1992-02-22|{010, 2222, 2222}|\n",
      "+------+---+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = spark.createDataFrame(data=data, schema=schema)\n",
    "df4.printSchema()\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d947b3-4346-4c63-afca-c17bdc69af9f",
   "metadata": {},
   "source": [
    "- schema 접근\n",
    "    - df.schema\n",
    "    - json()이용해서 json으로 변환 후 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85b8bfe7-d110-420a-a7d5-31c8c7313531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"fields\":[{\"metadata\":{\"desc\":\"\\uc774\\ub984\"},\"name\":\"name\",\"nullable\":false,\"type\":\"string\"},{\"metadata\":{\"desc\":\"\\ub098\\uc774\"},\"name\":\"age\",\"nullable\":false,\"type\":\"integer\"},{\"metadata\":{\"desc\":\"\\uc0dd\\uc77c\"},\"name\":\"birth\",\"nullable\":false,\"type\":\"date\"},{\"metadata\":{\"desc\":\"\\uc0dd\\uc77c\"},\"name\":\"phone\",\"nullable\":false,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"phone1\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"phone2\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"phone3\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}}],\"type\":\"struct\"}\n",
      "-----------------------------------------------------\n",
      "{\"fields\":[{\"metadata\":{\"desc\":\"이름\"},\"name\":\"name\",\"nullable\":false,\"type\":\"string\"},{\"metadata\":{\"desc\":\"나이\"},\"name\":\"age\",\"nullable\":false,\"type\":\"integer\"},{\"metadata\":{\"desc\":\"생일\"},\"name\":\"birth\",\"nullable\":false,\"type\":\"date\"},{\"metadata\":{\"desc\":\"생일\"},\"name\":\"phone\",\"nullable\":false,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"phone1\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"phone2\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"phone3\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}}],\"type\":\"struct\"}\n"
     ]
    }
   ],
   "source": [
    "# 스키마를 json으로 변환하여 확인\n",
    "df4_json = df4.schema.json()\n",
    "\n",
    "# 이름 => \\uc774\\ub984  유니코드로 나온다\n",
    "print(df4_json)\n",
    "print('-----------------------------------------------------')\n",
    "print(df4_json.encode().decode('unicode_escape'))\n",
    "# 바이트코드로 변환한 뒤 다시 문자열 디코딩을 할 때 unicode_escape 옵션을 추가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdcb87b-2e24-418d-aa36-deecfcd29f41",
   "metadata": {},
   "source": [
    "### spark.df의 각 컬럼 data type확인\n",
    "- dtypes 속성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "247cc4fd-b657-47c3-9974-d1b45119e96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'),\n",
       " ('age', 'int'),\n",
       " ('birth', 'date'),\n",
       " ('phone', 'struct<phone1:string,phone2:string,phone3:string>')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8485e30",
   "metadata": {},
   "source": [
    "## Pandas DataFrame으로 생성\n",
    "- pd dataframe을 spark dataframe으로 변환\n",
    "- spark.createDataFrame(pdDF)을 이용해서 진행\n",
    "- sparkDF로 변환 시 pd.DataFrame.iteritems 속성값을 전달해야함\n",
    "    - pd.iteritems는 pd.DataFrame의 items라는 속성에 값이 들어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9d69318-f98a-4248-b8ee-f8ae34f3c515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>김철수</td>\n",
       "      <td>20</td>\n",
       "      <td>2022-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이제동</td>\n",
       "      <td>21</td>\n",
       "      <td>2022-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>김명운</td>\n",
       "      <td>22</td>\n",
       "      <td>2022-07-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name  age       birth\n",
       "0  김철수   20  2022-07-01\n",
       "1  이제동   21  2022-07-02\n",
       "2  김명운   22  2022-07-03"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df = pd.DataFrame({\n",
    "    'name':['김철수','이제동','김명운'],\n",
    "    'age':[20, 21, 22],\n",
    "    'birth':[date(2022,7,1),date(2022,7,2),date(2022,7,3)]\n",
    "})\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e7f5929-eb96-4562-9cd6-7eaf7bcadda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "269cd4d8-9239-4d4f-a703-d6d8d46faea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## pandas 2.0 버전 이상부터 iteritems atrr이 items로 변경됨\n",
    "# sprk.createDataFrame은 pd.DataFrame.iteritems를 사용하므로 변경 반영 후 사용해야 함\n",
    "# pandas에 저장되어있는 속성값을 직접 설정하는 코드\n",
    "pd.DataFrame.iteritems = pd.DataFrame.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8638f584-8256-4b84-a321-6ae39c4de808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, age: bigint, birth: date]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  name|age|     birth|\n",
      "+------+---+----------+\n",
      "|김철수| 20|2022-07-01|\n",
      "|이제동| 21|2022-07-02|\n",
      "|김명운| 22|2022-07-03|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pd_sp = spark.createDataFrame(pandas_df)\n",
    "df_pd_sp\n",
    "df_pd_sp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec6a6f",
   "metadata": {},
   "source": [
    "## spark.DataFrame -> pandas.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2853cec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 스파크의 DataFrame을 사용하는 것이 성능상 더 이득\n",
    "# 스파크는 병렬처리도 해주고... 쿼리실행 최적화도 해주고...\n",
    "# 하지만 스파크 api가 Pandas에 비해 제공되는 기능이 적어서\n",
    "# Pandas를 써야만 해결이 가능하다면 Pandas로 가공 이후 스파크 DataFrame으로 변환도 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1729990c",
   "metadata": {},
   "source": [
    "## DataFrame -> pyspark.pandas\n",
    "- sparkdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b7d832a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>김철수</td>\n",
       "      <td>20</td>\n",
       "      <td>2022-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이제동</td>\n",
       "      <td>21</td>\n",
       "      <td>2022-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>김명운</td>\n",
       "      <td>22</td>\n",
       "      <td>2022-07-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name  age       birth\n",
       "0  김철수   20  2022-07-01\n",
       "1  이제동   21  2022-07-02\n",
       "2  김명운   22  2022-07-03"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp_pd = df_pd_sp.toPandas()\n",
    "df_sp_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047333df-60c8-4e76-a4bb-8a120d56fa4f",
   "metadata": {},
   "source": [
    "### pyspark.pandas dataframe -> spark.dataframe\n",
    "- to_pandas_on_spark()\n",
    "    - pyarrow timezone을 무시하도록 변경\n",
    "    - numpy 2.0이상 버전에서는 에러 발생\n",
    "    - numpy 2.0미만으로 downgrade해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6fe223bc-94e6-49e2-8a05-487f0056f84a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "anyio                     4.8.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 3.0.0\n",
      "async-lru                 2.0.4\n",
      "attrs                     24.3.0\n",
      "babel                     2.16.0\n",
      "beautifulsoup4            4.12.3\n",
      "bleach                    6.2.0\n",
      "certifi                   2024.12.14\n",
      "cffi                      1.17.1\n",
      "charset-normalizer        3.4.1\n",
      "click                     8.1.8\n",
      "comm                      0.2.2\n",
      "contourpy                 1.3.1\n",
      "cycler                    0.12.1\n",
      "dbus-python               1.2.18\n",
      "debugpy                   1.8.11\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "distro                    1.7.0\n",
      "exceptiongroup            1.2.2\n",
      "executing                 2.1.0\n",
      "fastjsonschema            2.21.1\n",
      "fonttools                 4.55.3\n",
      "fqdn                      1.5.1\n",
      "h11                       0.14.0\n",
      "httpcore                  1.0.7\n",
      "httpx                     0.28.1\n",
      "idna                      3.10\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.31.0\n",
      "ipywidgets                8.1.5\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.2\n",
      "Jinja2                    3.1.5\n",
      "joblib                    1.4.2\n",
      "json5                     0.10.0\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2024.10.1\n",
      "jupyter                   1.1.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter-console           6.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.11.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.15.0\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.3.4\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "jupyterlab_widgets        3.0.13\n",
      "kiwisolver                1.4.8\n",
      "MarkupSafe                3.0.2\n",
      "matplotlib                3.10.0\n",
      "matplotlib-inline         0.1.7\n",
      "mistune                   3.1.0\n",
      "nbclient                  0.10.2\n",
      "nbconvert                 7.16.5\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "nltk                      3.9.1\n",
      "notebook                  7.3.2\n",
      "notebook_shim             0.2.4\n",
      "numpy                     1.26.4\n",
      "overrides                 7.7.0\n",
      "packaging                 24.2\n",
      "pandas                    2.2.3\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.4\n",
      "pexpect                   4.9.0\n",
      "pillow                    11.1.0\n",
      "pip                       22.0.2\n",
      "platformdirs              4.3.6\n",
      "prometheus_client         0.21.1\n",
      "prompt_toolkit            3.0.48\n",
      "psutil                    6.1.1\n",
      "ptyprocess                0.7.0\n",
      "pure_eval                 0.2.3\n",
      "py4j                      0.10.9.5\n",
      "pyarrow                   18.1.0\n",
      "pycparser                 2.22\n",
      "Pygments                  2.19.1\n",
      "PyGObject                 3.42.1\n",
      "pyparsing                 3.2.1\n",
      "pyspark                   3.2.4\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        3.2.1\n",
      "pytz                      2024.2\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.2.0\n",
      "qtconsole                 5.6.1\n",
      "QtPy                      2.4.2\n",
      "referencing               0.35.1\n",
      "regex                     2024.11.6\n",
      "requests                  2.32.3\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.22.3\n",
      "Send2Trash                1.8.3\n",
      "setuptools                59.6.0\n",
      "six                       1.17.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.6\n",
      "ssh-import-id             5.11\n",
      "stack-data                0.6.3\n",
      "terminado                 0.18.1\n",
      "tinycss2                  1.4.0\n",
      "tomli                     2.2.1\n",
      "tornado                   6.4.2\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "types-python-dateutil     2.9.0.20241206\n",
      "typing_extensions         4.12.2\n",
      "tzdata                    2024.2\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.3.0\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.11.1\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "wheel                     0.37.1\n",
      "widgetsnbextension        4.0.13\n",
      "wordcloud                 1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "756c9c3e-13c9-4eca-ab17-ff1e072ac420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install pyarrow>=4.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c9d8e953-32a1-4e3d-b919-d0c08f4b8ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.2.1\n",
      "Uninstalling numpy-2.2.1:\n",
      "  Would remove:\n",
      "    /usr/local/bin/f2py\n",
      "    /usr/local/bin/numpy-config\n",
      "    /usr/local/lib/python3.10/dist-packages/numpy-2.2.1.dist-info/*\n",
      "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libgfortran-040039e1-0352e75f.so.5.0.0\n",
      "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libquadmath-96973f99-934c22de.so.0.0.0\n",
      "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libscipy_openblas64_-6bb31eeb.so\n",
      "    /usr/local/lib/python3.10/dist-packages/numpy/*\n",
      "^Coceed (Y/n)? \n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# numpy 2.0이상이라 에러 발생 -> 다운그레이드 진행\n",
    "# 터미널에서 pip uninstall numpy / pip install \"numpy<2.0\"진행 / !pip install로 확인\n",
    "# 버전 변경 후 커널/서버 재시작해야 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "826ebe22-bb5d-4887-9ec4-9a491484be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYARROW_IGNORE_TIMEZONE']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0e0e6de-ffe0-41d3-bd85-e9bca1914da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "`np.NaN` was removed in the NumPy 2.0 release. Use `np.nan` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_pd_sp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas_on_spark\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/python/pyspark/sql/dataframe.py:5729\u001b[0m, in \u001b[0;36mDataFrame.to_pandas_on_spark\u001b[0;34m(self, index_col)\u001b[0m\n\u001b[1;32m   5722\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_pandas_on_spark\u001b[39m(\n\u001b[1;32m   5723\u001b[0m     \u001b[38;5;28mself\u001b[39m, index_col: Optional[Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   5724\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandasOnSparkDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   5725\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   5726\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.to_pandas_on_spark is deprecated. Use DataFrame.pandas_api instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5727\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   5728\u001b[0m     )\n\u001b[0;32m-> 5729\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/python/pyspark/sql/dataframe.py:5781\u001b[0m, in \u001b[0;36mDataFrame.pandas_api\u001b[0;34m(self, index_col)\u001b[0m\n\u001b[1;32m   5731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpandas_api\u001b[39m(\n\u001b[1;32m   5732\u001b[0m     \u001b[38;5;28mself\u001b[39m, index_col: Optional[Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   5733\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandasOnSparkDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   5734\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5735\u001b[0m \u001b[38;5;124;03m    Converts the existing DataFrame into a pandas-on-Spark DataFrame.\u001b[39;00m\n\u001b[1;32m   5736\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;124;03m    16     Bob\u001b[39;00m\n\u001b[1;32m   5780\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5781\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnamespace\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _get_index_map\n\u001b[1;32m   5782\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame \u001b[38;5;28;01mas\u001b[39;00m PandasOnSparkDataFrame\n\u001b[1;32m   5783\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InternalFrame\n",
      "File \u001b[0;32m~/spark/python/pyspark/pandas/__init__.py:60\u001b[0m\n\u001b[1;32m     57\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYARROW_IGNORE_TIMEZONE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Index\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CategoricalIndex\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatetimes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatetimeIndex\n",
      "File \u001b[0;32m~/spark/python/pyspark/pandas/indexes/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Licensed to the Apache Software Foundation (ASF) under one or more\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# contributor license agreements.  See the NOTICE file distributed with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Index  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatetimes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatetimeIndex  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulti\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiIndex  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/spark/python/pyspark/pandas/indexes/base.py:66\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MissingPandasLikeIndex\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Series, first_series\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccessors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkIndexMethods\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     69\u001b[0m     is_name_like_tuple,\n\u001b[1;32m     70\u001b[0m     is_name_like_value,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     log_advice,\n\u001b[1;32m     79\u001b[0m )\n",
      "File \u001b[0;32m~/spark/python/pyspark/pandas/series.py:118\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspark\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functions \u001b[38;5;28;01mas\u001b[39;00m SF\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccessors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkSeriesMethods\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstrings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringMethods\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypedef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    120\u001b[0m     infer_return_type,\n\u001b[1;32m    121\u001b[0m     spark_type_to_pandas_dtype,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m     create_type_for_series_type,\n\u001b[1;32m    125\u001b[0m )\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypedef\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypehints\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m as_spark_type\n",
      "File \u001b[0;32m~/spark/python/pyspark/pandas/strings.py:44\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mps\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspark\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functions \u001b[38;5;28;01mas\u001b[39;00m SF\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mStringMethods\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"String methods for pandas-on-Spark Series\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, series: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mps.Series\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/spark/python/pyspark/pandas/strings.py:1332\u001b[0m, in \u001b[0;36mStringMethods\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m s\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mljust(width, fillchar)\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mpandas_on_spark\u001b[38;5;241m.\u001b[39mtransform_batch(pandas_ljust)\n\u001b[0;32m-> 1332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmatch\u001b[39m(\u001b[38;5;28mself\u001b[39m, pat: \u001b[38;5;28mstr\u001b[39m, case: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, na: Any \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNaN\u001b[49m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mps.Series\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;124;03m    Determine if each string matches a regular expression.\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1393\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpandas_match\u001b[39m(s) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ps\u001b[38;5;241m.\u001b[39mSeries[\u001b[38;5;28mbool\u001b[39m]:  \u001b[38;5;66;03m# type: ignore[no-untyped-def]\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __expired_attributes__:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` was removed in the NumPy 2.0 release. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__expired_attributes__[attr]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    403\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     )\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchararray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    407\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`np.chararray` is deprecated and will be removed from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe main namespace in the future. Use an array with a string \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor bytes dtype instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: `np.NaN` was removed in the NumPy 2.0 release. Use `np.nan` instead."
     ]
    }
   ],
   "source": [
    "# 모듈이 오래된 모듈, pyspark df를 활용 가능한 모듈이기 때문에 파이프라인 ETL위해서 모듈 사용이 가능한 상황을 만들고 있음. \n",
    "df_pd_sp.to_pandas_on_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccba3fc1",
   "metadata": {},
   "source": [
    "## 외부파일을 사용해 DataFrame 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bed5830f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------------+--------+-----------+-------------+\n",
      "|class_cd|school|class_std_cnt|     loc|school_type|teaching_type|\n",
      "+--------+------+-------------+--------+-----------+-------------+\n",
      "|     6OL| ANKYI|           20|   Urban| Non-public|     Standard|\n",
      "|     ZNS| ANKYI|           21|   Urban| Non-public|     Standard|\n",
      "|     2B1| CCAAW|           18|Suburban| Non-public| Experimental|\n",
      "+--------+------+-------------+--------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "class_df = spark.read.csv('/dataframe/a_class_info.csv', header=True)\n",
    "type(class_df)\n",
    "class_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e253e-f7d2-4330-b614-a54a3e7dee04",
   "metadata": {},
   "source": [
    "### SPARK.SQL.DATAFRAME SHOW() \n",
    "- def show( : 20개의 행을 표시)\n",
    "- def show(numRows : scala.Int) : 정해진 수 만큼 행 표시\n",
    "- def show(truncate : scala.Boolean) : 열값이 길어 모두 표현되지 않을경우 표현 여부\n",
    "    - truncate : True -> 열값을 자르고 표시 / False -> 열값을 모두 표시\n",
    "- def show(numRows : scala.Int, truncate : scala.Boolean) : 표현할 행과 열값을 자를것인지의 여부\n",
    "- def show(numRows : scala.Int, truncate : scala.Int ) : 표현할 행과 열값을 몇 글자 보여줄 것인지 여\n",
    "- def show(numRows : scala.Int, truncate : scala.Int, vertical : scala.Boolean) : 레코드별로 세로로 표시할 \n",
    "- 모든 행을 표현하고자 한다면\n",
    "    - count()사용해 행 수를 얻어와서 show()로 연결해야 함\n",
    "    - def show(df.count())것인지의 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b8e16ee-081b-4232-928d-7b0446f2f660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------------+--------+-----------+-------------+\n",
      "|class_cd|school|class_std_cnt|     loc|school_type|teaching_type|\n",
      "+--------+------+-------------+--------+-----------+-------------+\n",
      "|     6OL| ANKYI|           20|   Urban| Non-public|     Standard|\n",
      "|     ZNS| ANKYI|           21|   Urban| Non-public|     Standard|\n",
      "|     2B1| CCAAW|           18|Suburban| Non-public| Experimental|\n",
      "|     EPS| CCAAW|           20|Suburban| Non-public| Experimental|\n",
      "|     IQN| CCAAW|           15|Suburban| Non-public| Experimental|\n",
      "|     PGK| CCAAW|           21|Suburban| Non-public|     Standard|\n",
      "|     UHU| CCAAW|           16|Suburban| Non-public| Experimental|\n",
      "|     UWK| CCAAW|           19|Suburban| Non-public|     Standard|\n",
      "|     A33| CIMBB|           19|   Urban| Non-public|     Standard|\n",
      "|     EID| CIMBB|           21|   Urban| Non-public|     Standard|\n",
      "|     HUJ| CIMBB|           17|   Urban| Non-public| Experimental|\n",
      "|     PC6| CIMBB|           17|   Urban| Non-public|     Standard|\n",
      "|     1Q1| CUQAM|           28|   Urban|     Public|     Standard|\n",
      "|     BFY| CUQAM|           27|   Urban|     Public|     Standard|\n",
      "|     OMI| CUQAM|           28|   Urban|     Public|     Standard|\n",
      "|     X6Z| CUQAM|           24|   Urban|     Public| Experimental|\n",
      "|     2AP| DNQDD|           27|Suburban|     Public|     Standard|\n",
      "|     PW5| DNQDD|           20|Suburban|     Public| Experimental|\n",
      "|     ROP| DNQDD|           28|Suburban|     Public| Experimental|\n",
      "|     ST7| DNQDD|           20|Suburban|     Public|     Standard|\n",
      "|     XXJ| DNQDD|           27|Suburban|     Public|     Standard|\n",
      "|     197| FBUMG|           14|   Rural| Non-public| Experimental|\n",
      "|     5LQ| FBUMG|           18|   Rural| Non-public| Experimental|\n",
      "|     JGD| FBUMG|           14|   Rural| Non-public| Experimental|\n",
      "|     HCB| GJJHK|           22|Suburban|     Public|     Standard|\n",
      "|     NOR| GJJHK|           27|Suburban|     Public| Experimental|\n",
      "|     X78| GJJHK|           21|Suburban|     Public|     Standard|\n",
      "|     YUC| GJJHK|           21|Suburban|     Public|     Standard|\n",
      "|     ZDT| GJJHK|           27|Suburban|     Public|     Standard|\n",
      "|     ENO| GOKXL|           22|   Rural|     Public| Experimental|\n",
      "|     TSA| GOKXL|           23|   Rural|     Public| Experimental|\n",
      "|     VA6| GOKXL|           19|   Rural|     Public|     Standard|\n",
      "|     18K| GOOBU|           31|   Urban|     Public|     Standard|\n",
      "|     CXC| GOOBU|           24|   Urban|     Public|     Standard|\n",
      "|     HKF| GOOBU|           28|   Urban|     Public|     Standard|\n",
      "|     PBA| GOOBU|           24|   Urban|     Public|     Standard|\n",
      "|     U6J| GOOBU|           25|   Urban|     Public|     Standard|\n",
      "|     W8A| GOOBU|           26|   Urban|     Public| Experimental|\n",
      "|     05H| IDGFP|           22|   Urban| Non-public|     Standard|\n",
      "|     98D| IDGFP|           21|   Urban| Non-public| Experimental|\n",
      "|     G2L| IDGFP|           17|   Urban| Non-public|     Standard|\n",
      "|     P2A| IDGFP|           17|   Urban| Non-public| Experimental|\n",
      "|     XZM| IDGFP|           17|   Urban| Non-public|     Standard|\n",
      "|     1VD| KFZMY|           27|   Urban| Non-public| Experimental|\n",
      "|     21Q| KFZMY|           25|   Urban| Non-public|     Standard|\n",
      "|     2BR| KZKKE|           20|   Rural|     Public|     Standard|\n",
      "|     3D0| KZKKE|           22|   Rural|     Public|     Standard|\n",
      "|     5JK| KZKKE|           24|   Rural|     Public|     Standard|\n",
      "|     O6A| KZKKE|           22|   Rural|     Public|     Standard|\n",
      "|     QTU| KZKKE|           23|   Rural|     Public|     Standard|\n",
      "|     AJ1| LAYPA|           21|   Rural|     Public|     Standard|\n",
      "|     J8J| LAYPA|           19|   Rural|     Public|     Standard|\n",
      "|     MDS|  NULL|           18|   Rural| Non-public|     Standard|\n",
      "|     MDE|  NULL|           10|   Rural| Non-public| Experimental|\n",
      "|     RA5| LAYPA|           17|   Rural|     Public| Experimental|\n",
      "|     5SZ| OJOBU|           17|   Rural|     Public| Experimental|\n",
      "|     6U9| OJOBU|           22|   Rural|     Public|     Standard|\n",
      "|     6PP|  NULL|         NULL|    NULL|       NULL|         NULL|\n",
      "|     4SZ|  NULL|         NULL|    NULL|       NULL|         NULL|\n",
      "|     5SD|  NULL|         NULL|    NULL|       NULL|         NULL|\n",
      "|     FS3| OJOBU|           19|   Rural|     Public|     Standard|\n",
      "|     XJ8| OJOBU|           23|   Rural|     Public|     Standard|\n",
      "|     0N7| QOQTS|           28|   Urban|     Public| Experimental|\n",
      "|     3XJ| QOQTS|           24|   Urban|     Public|     Standard|\n",
      "|     RK7| QOQTS|           22|   Urban|     Public|     Standard|\n",
      "|     SUR| QOQTS|           28|   Urban|     Public|     Standard|\n",
      "|     X2O| QOQTS|           25|   Urban|     Public| Experimental|\n",
      "|     XZ4| QOQTS|           22|   Urban|     Public|     Standard|\n",
      "|     1SZ| UAGPU|           22|Suburban|     Public|     Standard|\n",
      "|     62L| UAGPU|           23|Suburban|     Public|     Standard|\n",
      "|     NWZ| UAGPU|           21|Suburban|     Public|     Standard|\n",
      "|     S98| UAGPU|           21|Suburban|     Public|     Standard|\n",
      "|     08N| UKPGS|           21|Suburban|     Public|     Standard|\n",
      "|     9AW| UKPGS|           25|Suburban|     Public|     Standard|\n",
      "|     IPU| UKPGS|           19|Suburban|     Public| Experimental|\n",
      "|     KXB| UKPGS|           18|Suburban|     Public| Experimental|\n",
      "|     PGH| UKPGS|           23|Suburban|     Public| Experimental|\n",
      "|     XXE| UKPGS|           22|Suburban|     Public|     Standard|\n",
      "|     6C1| UUUQX|           16|Suburban| Non-public|     Standard|\n",
      "|     AE1| UUUQX|           17|Suburban| Non-public| Experimental|\n",
      "|     H7S| UUUQX|           16|Suburban| Non-public| Experimental|\n",
      "|     P8I| UUUQX|           20|Suburban| Non-public|     Standard|\n",
      "|     SSP| UUUQX|           15|Suburban| Non-public|     Standard|\n",
      "|     CD8| VHDHF|           20|   Rural| Non-public| Experimental|\n",
      "|     J6X| VHDHF|           16|   Rural| Non-public|     Standard|\n",
      "|     KR1| VHDHF|           15|   Rural| Non-public| Experimental|\n",
      "|     341| VKWQH|           18|   Rural|     Public|     Standard|\n",
      "|     D33| VKWQH|           21|   Rural|     Public|     Standard|\n",
      "|     DFQ| VKWQH|           19|   Rural|     Public| Experimental|\n",
      "|     GYM| VKWQH|           20|   Rural|     Public|     Standard|\n",
      "|     IEM| VKWQH|           22|   Rural|     Public| Experimental|\n",
      "|     7BL| VVTVA|           29|   Urban|     Public|     Standard|\n",
      "|     A93| VVTVA|           30|   Urban|     Public| Experimental|\n",
      "|     TB5| VVTVA|           25|   Urban|     Public|     Standard|\n",
      "|     YTB| VVTVA|           30|   Urban|     Public| Experimental|\n",
      "|     1UU| ZMNYA|           24|Suburban|     Public| Experimental|\n",
      "|     4NN| ZMNYA|           22|Suburban|     Public|     Standard|\n",
      "|     V77| ZMNYA|           23|Suburban|     Public| Experimental|\n",
      "|     CII| ZOWMK|           27|   Urban|     Public|     Standard|\n",
      "|     Q0E| ZOWMK|           30|   Urban|     Public| Experimental|\n",
      "|     QA2| ZOWMK|           30|   Urban|     Public|     Standard|\n",
      "|     ZBH| ZOWMK|           30|   Urban|     Public|     Standard|\n",
      "+--------+------+-------------+--------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class_df.show() #20개 행 표시\n",
    "#class_df.count() #102개row\n",
    "#class_df.show(2, truncate=2) #2개행 표시, 열별2글자만 표현\n",
    "# class_df.show(2, truncate=False) #각 열의 값이 잘리는 것을 방지\n",
    "# class_df.show(2, vertical=True)\n",
    "# class_df.show(2, vertical=False) #vertical 기본값은 False\n",
    "class_df.show(class_df.count()) #전체 행 표시하려면 이렇게 전체행 값을 얻어와서 show를 돌려야만 가능.\n",
    "                                #모든 node data순회해서 결과 반환. --> 성능 떨어지게됨.\n",
    "                                #자주사용한다면 메모리에 상주시키고 사용하면 성능 up\n",
    "\n",
    "# collect(): 출력하고 list로 반환\n",
    "# show() 출력만 진행함, 반환값이 없으므로 type이 non type\n",
    "# type(class_df.show(2, vertical=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eb39b6",
   "metadata": {},
   "source": [
    "## spark.sql.DataFrame 컬럼 컨트롤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "096328b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    ('김철수', 15, date(2022,7,22), ('010','1111','2222')),\n",
    "    ('이제동', 20, date(2021,7,22), ('010','2222','3333')),\n",
    "    ('김명운', 25, date(2020,7,22), ('010','4444','5555')),\n",
    "    ('홍진호', 36, date(2018,7,22), ('010','3333','4444'))\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('name',StringType(),False,{'desc':'이름'}),\n",
    "    StructField('age',IntegerType(),False,{'desc':'나이'}),    \n",
    "    StructField('birth',DateType(),False,{'desc' :'생일'}),\n",
    "    StructField('phone', StructType([\n",
    "        StructField('phone1',StringType(),True),\n",
    "        StructField('phone2',StringType(),True),\n",
    "        StructField('phone3',StringType(),True)]),False,{'desc':'전화번호'}) # 중첩스키마\n",
    "])\n",
    "\n",
    "col_df = spark.createDataFrame(data, schema=schema)\n",
    "type(col_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be8a2250-8a51-4695-be42-93a7383f7b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+\n",
      "|  name|age|     birth|            phone|\n",
      "+------+---+----------+-----------------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|\n",
      "+------+---+----------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c56474",
   "metadata": {},
   "source": [
    "- withColumn\n",
    "    - 지연연산 모듈\n",
    "    - 연산계획에 참여함\n",
    "    - 기존 컬럼 업데이트, 타입 변경, 신규 컬럼 추가 가능\n",
    "    - withColumn('컬럼명', '값')\n",
    "    - 신규 또는 업데이트 값 줄 때 주의\n",
    "        - 신규 컬럼 값 타입 활용, 업데이트 진행시 기존 컬럼값 활용: col('컬럼명') -> 기존 컬럼의 값 참조 가능\n",
    "\n",
    "- withColumnRename()\n",
    "    - 컬럼명 변경 연산의 메소드\n",
    "\n",
    "- Spark의 lit function\n",
    "    - 모든 타입을 허용하는 함수\n",
    "    - 어떤 타입이 들어와도 객체로 인식하고 연산 진행 시 원하는 타입(유추타입)으로 변환 가능\n",
    "    - 지연연산을 진행하므로 추가되는 컬럼값에 대해 타입 바로 결정 불가능, lit()이용 객체등록 후 최적화시 타입 유추"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8801994b-f58f-40c4-a1e9-f4ea6ac9a134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+--------+\n",
      "|  name|age|     birth|            phone|우승여부|\n",
      "+------+---+----------+-----------------+--------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|        |\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|        |\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|        |\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|        |\n",
      "+------+---+----------+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lit : column 객체를 literal로 만들어주는 함수\n",
    "\n",
    "# 원하는 컬럼을 DataFrame에 추가\n",
    "#col_df.withColumn('우승여부', '').show() --> 이렇게 실행하면 ''을 str로 못읽어서 (값이 없으니 유추를 못해서) 에러난다.\n",
    "tmp = col_df.withColumn('우승여부', lit('')) # lit으로 객체등록을 하니 잘 진행된다.\n",
    "tmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25a5a635-9979-4d96-aaf5-52f9c77c8245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+\n",
      "|  name|age|     birth|            phone|\n",
      "+------+---+----------+-----------------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|\n",
      "+------+---+----------+-----------------+\n",
      "\n",
      "+------+---+----------+-----------------+--------+\n",
      "|  name|age|     birth|            phone|우승여부|\n",
      "+------+---+----------+-----------------+--------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|    우승|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|    우승|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|    우승|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|    우승|\n",
      "+------+---+----------+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 값을 지정해서 추가 - 컬럼의 모든 셀에 동일값 지정\n",
    "col_df.show()\n",
    "col_df.withColumn('우승여부',lit('우승')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74660979-60a7-432e-b32c-49203b4fed1c",
   "metadata": {},
   "source": [
    "### 파생컬럼 생성\n",
    "- 기존 컬럼값을 가공해서 새로운 컬럼을 추가\n",
    "- eg. age 값에 따라 '연령대'라는 컬럼을 추가\n",
    "- spark의 sql.dataframe 에서, if문(case문)처럼 사용할 수 있는 SQL function 제공\n",
    "  : when (+ otherwise )을 사용할 수 있음\n",
    "  - when을 if로, otherwise를 else로 생각하면 됨.\n",
    "  - when(조건1, 조건1이 참일 때 값).when(조건2, 조건2이 참일 때 값).otherwise(그 외 모든 경우의 값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f110eada-4fee-41e8-9360-c2210ba2b563",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'age'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = false)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- birth: date (nullable = false)\n",
      " |-- phone: struct (nullable = false)\n",
      " |    |-- phone1: string (nullable = true)\n",
      " |    |-- phone2: string (nullable = true)\n",
      " |    |-- phone3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# when - otherwise : 조건에 따라 원하는 컬럼객체를 반환\n",
    "col_df.age #연산 가능한 int타입\n",
    "col_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b36e25",
   "metadata": {},
   "source": [
    "### column  내용  변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07f30739",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+---------+\n",
      "|  name|age|     birth|            phone|   연령대|\n",
      "+------+---+----------+-----------------+---------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|     10대|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|     20대|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|     20대|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|30대 이상|\n",
      "+------+---+----------+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# when - otherwise : 조건에 따라 원하는 컬럼객체를 반환\n",
    "# 정수/정수 = 정수가 나올거라 예상했으나 실수가 반환되고 있음 ==> floor로 버림처리\n",
    "# col_df.age 했을 때, Column<'age'> 출력됨. 이 column객체와 연산이 가능한지 확인 vlfdy\n",
    "# 기존 df의 컬럼값 참조 위해서 col('컬럼명')사용 -> col('age') == Column('age') == df.age\n",
    "# Column객체로 참조하게 되면 각 셀의 값과 연산하는 토큰(리터럴)연산이 가능\n",
    "temp = col_df.withColumn('연령대', when(floor(col_df.age/10)==1, '10대')\n",
    "                                    .when(floor(col_df.age/10)==2, '20대')\n",
    "                                    .otherwise('30대 이상'))\n",
    "temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2232429f-f994-4af8-84a5-66d63d12af6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+---------+\n",
      "|  name|age|     birth|            phone|   연령대|\n",
      "+------+---+----------+-----------------+---------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|     10대|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|     20대|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|     20대|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|30대 이상|\n",
      "+------+---+----------+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 연령대 컬럼의 값을 다시 변경\n",
    "tmp = col_df.withColumn('연령대', when(floor(col_df.age/10)==1, '10대')\n",
    "                                    .when(floor(col_df.age/10)==2, '20대')\n",
    "                                    .otherwise('30대 이상'))\n",
    "tmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0aa57807-d274-4f5a-a130-98e7f4b97581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+------+\n",
      "|  name|age|     birth|            phone|연령대|\n",
      "+------+---+----------+-----------------+------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|청소년|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|  청년|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|  청년|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|  성인|\n",
      "+------+---+----------+-----------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+------+\n",
      "|  name|age|     birth|            phone|연령대|\n",
      "+------+---+----------+-----------------+------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|청소년|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|  청년|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|  청년|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|  성인|\n",
      "+------+---+----------+-----------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 기존 컬럼인 연령대 값을 변경 (tmp에 연령대의 연산 계획이 들어와있음)\n",
    "tmp.withColumn('연령대', when(floor(col('age')/10)==1, '청소년')\n",
    "                           .when(floor(col('age')/10)==2, '청년')\n",
    "                           .otherwise('성인')).show()\n",
    "\n",
    "# 위에처럼 col_df.age로 접근해서도 변경이 가능한지 확인해보자.\n",
    "tmp = tmp.withColumn('연령대', when(floor(col_df.age/10)==1, '청소년')\n",
    "                           .when(floor(col_df.age/10)==2, '청년')\n",
    "                           .otherwise('성인'))\n",
    "tmp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c4ae4f",
   "metadata": {},
   "source": [
    "### column 이름 변경\n",
    "- withColumnRenamed('변경전컬럼명','변경후컬럼명')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7337f18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+------+\n",
      "|  name|age|     birth|            phone|  분류|\n",
      "+------+---+----------+-----------------+------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|청소년|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|  청년|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|  청년|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|  성인|\n",
      "+------+---+----------+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.withColumnRenamed('연령대','분류').show() #컬럼명변경 연산계획을 저장하지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d077b939",
   "metadata": {},
   "source": [
    "### column  삭제\n",
    "- spark.spl.DF.drop(컬럼명)\n",
    "- 해당 컬럼이 없어도 연산처리시(action)에러 발생하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4f1ac71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+------+\n",
      "|  name|age|     birth|            phone|연령대|\n",
      "+------+---+----------+-----------------+------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|청소년|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|  청년|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|  청년|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|  성인|\n",
      "+------+---+----------+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = tmp.drop('분류') # 연령대를 분류로 변경하는 연산이 없는 상태에서 분류를 drop하라는 명령\n",
    "                        # 그러나 에러 발생하지 않고 그냥 무시\n",
    "tmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "116eae31-db00-477c-8fd6-d39d89ee6b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+\n",
      "|  name|age|     birth|            phone|\n",
      "+------+---+----------+-----------------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|\n",
      "+------+---+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = tmp.withColumnRenamed('연령대','분류')\n",
    "tmp = tmp.drop('분류')\n",
    "tmp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aedcf61",
   "metadata": {},
   "source": [
    "# 2. DataFrame 사용 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b533d543",
   "metadata": {},
   "source": [
    "참고 : https://spark.apache.org/docs/3.2.0/api/scala/org/apache/spark/sql/Dataset.html \n",
    "\n",
    "- DataFrame의 메서드의 구분\n",
    " - transformation\n",
    " - action\n",
    " - Basic Dataset functions  \n",
    " \n",
    " \n",
    "- DataFrame의 사용은 SQL 쿼리 구조를 따라간다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
